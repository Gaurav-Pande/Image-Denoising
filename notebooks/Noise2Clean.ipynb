{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Noise2Clean.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1vA-UFCd4uD",
        "colab_type": "code",
        "outputId": "23b3923b-37f4-4733-fa0c-2f7e5f276c87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sies68brly7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !unzip \"/content/CBSD68-dataset-master.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSoNrdaIly-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "random.seed(2)\n",
        "\n",
        "files = os.listdir(\"/content/CBSD68-dataset-master/CBSD68/original_png\")\n",
        "# files = [file[:-4] for file in files if \"real\" in file]\n",
        "\n",
        "random.shuffle(files)\n",
        "\n",
        "train = files[:50]\n",
        "val = files[50:59]\n",
        "test = files[59:]\n",
        "\n",
        "# print(len(files))\n",
        "\n",
        "train_df = pd.DataFrame({\"files\":train})\n",
        "train_df.to_csv(\"/content/train_data.csv\",index=None)\n",
        "\n",
        "val_df = pd.DataFrame({\"files\":val})\n",
        "val_df.to_csv(\"/content/val_data.csv\",index=None)\n",
        "\n",
        "test_df = pd.DataFrame({\"files\":test})\n",
        "test_df.to_csv(\"/content/test_data.csv\",index=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wchdQUzi7Vf3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "c0e6a6bb-aadd-4eeb-88d0-7f64db7efb3f"
      },
      "source": [
        "test_df"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>files</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0064.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0045.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0055.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0003.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0041.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0047.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0030.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0028.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0011.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      files\n",
              "0  0064.png\n",
              "1  0045.png\n",
              "2  0055.png\n",
              "3  0003.png\n",
              "4  0041.png\n",
              "5  0047.png\n",
              "6  0030.png\n",
              "7  0028.png\n",
              "8  0011.png"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beAQ-V8teAbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Project: ML 7641\n",
        "# Author: Sai Sateesh Gudapati\n",
        "\n",
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from skimage import io, transform\n",
        "from skimage.color import rgb2ycbcr\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import PIL\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "\n",
        "device = torch.device('cuda')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2zz9fZgeIGP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Define transforms\n",
        "\n",
        "class Rescale(object):\n",
        "    \"\"\"Rescale the image in a sample to a given size.\n",
        "\n",
        "    Args:\n",
        "        output_size (tuple or int): Desired output size. If tuple, output is\n",
        "            matched to output_size. If int, smaller of image edges is matched\n",
        "            to output_size keeping aspect ratio the same.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, output_size):\n",
        "        assert isinstance(output_size, (int, tuple))\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, n_image = sample['original_image'], sample['noisy_image']\n",
        "\n",
        "        h, w = image.shape[:2]\n",
        "        if isinstance(self.output_size, int):\n",
        "            if h > w:\n",
        "                new_h, new_w = self.output_size * h / w, self.output_size\n",
        "            else:\n",
        "                new_h, new_w = self.output_size, self.output_size * w / h\n",
        "        else:\n",
        "            new_h, new_w = self.output_size\n",
        "\n",
        "        new_h, new_w = int(new_h), int(new_w)\n",
        "\n",
        "        img = transform.resize(image, (new_h, new_w,1))\n",
        "        n_img = transform.resize(n_image,(new_h, new_w,1))\n",
        "        \n",
        "#         print(img.shape)\n",
        "\n",
        "        return {'noisy_image': n_img, 'original_image': img}\n",
        "\n",
        "\n",
        "class RandomCrop(object):\n",
        "    \"\"\"Crop randomly the image in a sample.\n",
        "\n",
        "    Args:\n",
        "        output_size (tuple or int): Desired output size. If int, square crop\n",
        "            is made.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, output_size):\n",
        "        assert isinstance(output_size, (int, tuple))\n",
        "        if isinstance(output_size, int):\n",
        "            self.output_size = (output_size, output_size)\n",
        "        else:\n",
        "            assert len(output_size) == 2\n",
        "            self.output_size = output_size\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, n_image = sample['original_image'], sample['noisy_image']\n",
        "\n",
        "        h, w = image.shape[:2]\n",
        "        new_h, new_w = self.output_size\n",
        "        # new_h, new_w = h,w\n",
        "\n",
        "        # print(h,new_h)\n",
        "\n",
        "        top = np.random.randint(0, h - new_h)\n",
        "        left = np.random.randint(0, w - new_w)\n",
        "\n",
        "        # top =0\n",
        "        # left =0\n",
        "\n",
        "        n_image = n_image[top: top + new_h,\n",
        "                      left: left + new_w]\n",
        "\n",
        "        # image = image[top: top + new_h,\n",
        "                      # left: left + new_w]\n",
        "\n",
        "        image = image[top+8: top + new_h-8,\n",
        "                      left+8: left + new_w-8]\n",
        "\n",
        "\n",
        "\n",
        "        s = self.output_size[0]\n",
        "        # image = transform.resize(image, (s, s,1))\n",
        "        # n_image = transform.resize(n_image,(s, s,1))\n",
        "\n",
        "        return {'original_image': image, 'noisy_image': n_image}\n",
        "\n",
        "\n",
        "\n",
        "class ToTensor(object):\n",
        "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, n_image = sample['original_image'], sample['noisy_image']\n",
        "\n",
        "        # swap color axis because\n",
        "        # numpy image: H x W x C\n",
        "        # torch image: C X H X W\n",
        "        image = image.transpose((2, 0, 1))\n",
        "        n_image = n_image.transpose((2, 0, 1))\n",
        "        return {'original_image': torch.from_numpy(image),\n",
        "                'noisy_image': torch.from_numpy(n_image)}\n",
        "\n",
        "\n",
        "# scale = Rescale((400,400))\n",
        "# to_tensor = ToTensor()\n",
        "composed = transforms.Compose([RandomCrop(33),ToTensor()])\n",
        "# composed = transforms.Compose([ToTensor()])\n",
        "\n",
        "# ## transforms\n",
        "# composed = transforms.Compose([transforms.RandomCrop(33),\n",
        "#                                transforms.RandomHorizontalFlip(),\n",
        "#                                transforms.RandomVerticalFlip(),\n",
        "#                                transforms.RandomRotation(90),\n",
        "#                                transforms.RandomRotation(180),\n",
        "#                                transforms.RandomRotation(270),\n",
        "#                                transforms.ToTensor()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-dROsEOed2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NoisyImageDataset(Dataset):\n",
        "    \"\"\"Using PASCAL VOC dataset to create Y,X samples.\"\"\"\n",
        "\n",
        "    def __init__(self, csv_file, root_dir, transform=composed):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with image names.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.image_data = pd.read_csv(csv_file)\n",
        "        # print(self.image_data)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_name = os.path.join(self.root_dir+\"/original_png\",\n",
        "                                self.image_data.iloc[idx, 0])\n",
        "        \n",
        "        n_img_name = os.path.join(self.root_dir+\"/noisy25\",\n",
        "                                self.image_data.iloc[idx, 0])\n",
        "        \n",
        "        image = io.imread(img_name)\n",
        "        # image = rgb2ycbcr(image)\n",
        "        image = image.astype(\"float64\")\n",
        "\n",
        "        noisy_image = io.imread(n_img_name)\n",
        "        noisy_image = noisy_image.astype(\"float64\")\n",
        "        \n",
        "        # print(noisy_image[:,:,0].shape)\n",
        "        # sample = {'noisy_image': noisy_image2, 'original_image': noisy_image}\n",
        "        sample = {'noisy_image': noisy_image, 'original_image': image}\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orX3p-OKefiS",
        "colab_type": "code",
        "outputId": "06a45c51-1257-440a-d2f1-3962e6115fae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "noise_dataset = NoisyImageDataset(\"/content/train_data.csv\",\"/content/CBSD68-dataset-master/CBSD68\")\n",
        "\n",
        "val_dataset = NoisyImageDataset(\"/content/val_data.csv\",\"/content/CBSD68-dataset-master/CBSD68\")\n",
        "\n",
        "o,n = noise_dataset[6].values()\n",
        "print(n.shape,o.shape)"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 33, 33]) torch.Size([3, 17, 17])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrogqAZBe9bd",
        "colab_type": "code",
        "outputId": "7eb30dff-81c7-4de7-a9d9-ce3652a5a3b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "## visualize crop transform\n",
        "\n",
        "# Apply each of the above transforms on sample.\n",
        "# fig = plt.figure()\n",
        "\n",
        "# crop = RandomCrop(256)\n",
        "sample = noise_dataset[10]\n",
        "\n",
        "plt.imshow(sample[\"noisy_image\"].numpy().astype(\"uint8\").transpose((1,2,0)))\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(sample[\"original_image\"].numpy().astype(\"uint8\").transpose((1,2,0)))\n",
        "plt.show()"
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nE0l1rGzeAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZqziKo4jAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nacDvMc3fH8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## create dataloader\n",
        "\n",
        "dataloader = DataLoader(noise_dataset, batch_size=16,\n",
        "                        shuffle=True, num_workers=4)\n",
        "\n",
        "valloader = DataLoader(val_dataset, batch_size=4,\n",
        "                        shuffle=True, num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjNFiWIvfTeQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Defining 3 layer DN-Resnet \n",
        "\n",
        "class DNNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DNNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=9, stride=1, padding=0),\n",
        "            nn.ReLU())\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 32, kernel_size=5, stride=1, padding=0),\n",
        "            nn.ReLU())\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(32, 3, kernel_size=5, stride=1, padding=0),\n",
        "            nn.ReLU())\n",
        "\n",
        "    ## forward pass\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wq4DNUVfnBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Output of the code\n",
        "class DNNet_res(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DNNet_res, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=9, stride=1, padding=0),\n",
        "            nn.ReLU())\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 32, kernel_size=5, stride=1, padding=0),\n",
        "            nn.ReLU())\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(32, 3, kernel_size=5, stride=1, padding=0),\n",
        "            nn.ReLU())\n",
        "        self.res_layer1 = nn.Sequential(nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU())\n",
        "        # nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.res_layer2 = nn.Sequential(nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1))\n",
        "        self.rel_layer = nn.Sequential(nn.ReLU())\n",
        "\n",
        "    ## forward pass\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        res1 = self.res_layer1(out)\n",
        "        res2 = self.res_layer2(res1)\n",
        "        out = self.rel_layer(out+res2)\n",
        "        res3 = self.res_layer1(out)\n",
        "        res4 = self.res_layer2(res3)\n",
        "        out = self.rel_layer(out+res4)\n",
        "        res5 = self.res_layer1(out)\n",
        "        res6 = self.res_layer2(res5)\n",
        "        out = self.rel_layer(out+res6)\n",
        "        out = self.layer3(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrxiTdDSfySm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## define model\n",
        "\n",
        "model = DNNet()\n",
        "model = model.double()\n",
        "model.to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr7E8xgnr_61",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## resned model\n",
        "model2 = DNNet_res()\n",
        "model2 = model2.double()\n",
        "model2.to(device)\n",
        "\n",
        "# model_dict = model2.state_dict()\n",
        "# model_dict.update(model.state_dict())\n",
        "# model2.load_state_dict(model_dict)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model2.parameters(), lr=0.0001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ONQNl-usDAy",
        "colab_type": "code",
        "outputId": "f3bb6e38-3999-4a55-f1b9-73329e60edc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_weights = torch.load(\"/content/drive/My Drive/dn_resnet_200.pt\")\n",
        "model2.load_state_dict(model_weights)"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7ubA_o8sDDa",
        "colab_type": "code",
        "outputId": "9de4ccc0-5151-42a1-e2d7-2df6c6bb0ee8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import time\n",
        "# Train the model\n",
        "total_step = len(dataloader)\n",
        "step_loss_list = []\n",
        "train_loss_list = []\n",
        "val_loss_list = []\n",
        "num_epochs = 1000\n",
        "\n",
        "training_start_time = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = 0\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        step_start_time = time.time()\n",
        "        # Run the forward pass\n",
        "        images = batch['noisy_image'].to(device)\n",
        "        labels = batch['original_image'].to(device)\n",
        "        outputs = model2(images)\n",
        "        # print(outputs.shape,labels.shape)\n",
        "        loss = criterion(outputs, labels)\n",
        "        step_loss_list.append(loss.item())\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "        # Backprop and perform Adam optimisation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # time_per_step = time.time() - step_start_time\n",
        "\n",
        "        # if (i + 1) % 10 == 0:\n",
        "          # print(i)\n",
        "            # print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Time_per_step: {:.2f}s'\n",
        "                  # .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),time_per_step))\n",
        "\n",
        "    # print(\"Training loss = {:.2f} at Epoch {}\".format(train_loss / total_step,epoch+1))\n",
        "    \n",
        "    train_loss_list.append(train_loss)\n",
        "    #At the end of the epoch, do a pass on the validation set\n",
        "    total_val_loss = 0\n",
        "    for i, batch in enumerate(valloader):\n",
        "        images = batch['noisy_image'].to(device)\n",
        "        labels = batch['original_image'].to(device)\n",
        "        # #Wrap tensors in Variables\n",
        "        # inputs, labels = Variable(inputs), Variable(labels)\n",
        "        \n",
        "        #Forward pass\n",
        "        val_outputs = model2(images)\n",
        "        val_loss = criterion(val_outputs, labels)\n",
        "        total_val_loss += val_loss.item()\n",
        "    \n",
        "    val_loss_list.append(total_val_loss)\n",
        "    print(\"Training loss = {:.4f} || Validation loss = {:.4f} at Epoch {}\".format(train_loss / total_step,total_val_loss / len(valloader),epoch+1))\n",
        "\n",
        "    if (epoch+1)%50 == 0:\n",
        "      # torch.save(model.state_dict(), \"/content/drive/My Drive/nac_bsd_dn_resnet_{}.pt\".format(epoch+1))\n",
        "      loss_dict = {\"train_loss\":train_loss_list,\"val_loss\":val_loss_list}\n",
        "      # output = open('/content/drive/My Drive/nac_bsd_dn_resnet_{}.pkl'.format(epoch+1), 'wb')\n",
        "      # pickle.dump(loss_dict, output)\n",
        "      # output.close()  \n",
        "\n",
        "print(\"Training finished, took {:.2f}s\".format(time.time() - training_start_time))"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss = 214.3865 || Validation loss = 279.4498 at Epoch 1\n",
            "Training loss = 182.8965 || Validation loss = 299.6533 at Epoch 2\n",
            "Training loss = 192.2260 || Validation loss = 219.7187 at Epoch 3\n",
            "Training loss = 158.8138 || Validation loss = 265.1544 at Epoch 4\n",
            "Training loss = 177.1780 || Validation loss = 258.6014 at Epoch 5\n",
            "Training loss = 173.3164 || Validation loss = 275.6023 at Epoch 6\n",
            "Training loss = 152.9936 || Validation loss = 183.5387 at Epoch 7\n",
            "Training loss = 203.9799 || Validation loss = 234.2238 at Epoch 8\n",
            "Training loss = 214.5416 || Validation loss = 139.4678 at Epoch 9\n",
            "Training loss = 169.9203 || Validation loss = 172.8578 at Epoch 10\n",
            "Training loss = 222.9983 || Validation loss = 251.9817 at Epoch 11\n",
            "Training loss = 221.0052 || Validation loss = 291.5986 at Epoch 12\n",
            "Training loss = 196.2627 || Validation loss = 265.7325 at Epoch 13\n",
            "Training loss = 162.5286 || Validation loss = 206.1296 at Epoch 14\n",
            "Training loss = 209.9274 || Validation loss = 107.6144 at Epoch 15\n",
            "Training loss = 206.6065 || Validation loss = 223.6146 at Epoch 16\n",
            "Training loss = 199.4795 || Validation loss = 163.1058 at Epoch 17\n",
            "Training loss = 178.0178 || Validation loss = 195.1475 at Epoch 18\n",
            "Training loss = 190.2324 || Validation loss = 121.8020 at Epoch 19\n",
            "Training loss = 188.6294 || Validation loss = 114.8250 at Epoch 20\n",
            "Training loss = 143.7419 || Validation loss = 242.2379 at Epoch 21\n",
            "Training loss = 174.6386 || Validation loss = 142.9919 at Epoch 22\n",
            "Training loss = 152.6131 || Validation loss = 193.5880 at Epoch 23\n",
            "Training loss = 187.4228 || Validation loss = 157.5496 at Epoch 24\n",
            "Training loss = 189.7950 || Validation loss = 228.7723 at Epoch 25\n",
            "Training loss = 159.0697 || Validation loss = 215.9023 at Epoch 26\n",
            "Training loss = 164.9493 || Validation loss = 190.8896 at Epoch 27\n",
            "Training loss = 151.6752 || Validation loss = 270.3440 at Epoch 28\n",
            "Training loss = 166.5888 || Validation loss = 176.1485 at Epoch 29\n",
            "Training loss = 176.6101 || Validation loss = 308.0946 at Epoch 30\n",
            "Training loss = 183.5975 || Validation loss = 255.6610 at Epoch 31\n",
            "Training loss = 159.0746 || Validation loss = 180.0677 at Epoch 32\n",
            "Training loss = 203.3745 || Validation loss = 130.0190 at Epoch 33\n",
            "Training loss = 169.2271 || Validation loss = 223.3188 at Epoch 34\n",
            "Training loss = 198.3853 || Validation loss = 329.4586 at Epoch 35\n",
            "Training loss = 138.9051 || Validation loss = 168.9111 at Epoch 36\n",
            "Training loss = 160.9878 || Validation loss = 302.7548 at Epoch 37\n",
            "Training loss = 165.8400 || Validation loss = 272.2975 at Epoch 38\n",
            "Training loss = 146.9551 || Validation loss = 198.9593 at Epoch 39\n",
            "Training loss = 211.9035 || Validation loss = 235.4902 at Epoch 40\n",
            "Training loss = 173.4641 || Validation loss = 199.2220 at Epoch 41\n",
            "Training loss = 158.0481 || Validation loss = 129.5291 at Epoch 42\n",
            "Training loss = 185.7025 || Validation loss = 257.9477 at Epoch 43\n",
            "Training loss = 167.8181 || Validation loss = 183.8184 at Epoch 44\n",
            "Training loss = 166.9140 || Validation loss = 226.7910 at Epoch 45\n",
            "Training loss = 137.1620 || Validation loss = 205.9868 at Epoch 46\n",
            "Training loss = 152.0372 || Validation loss = 247.1807 at Epoch 47\n",
            "Training loss = 156.0372 || Validation loss = 314.2995 at Epoch 48\n",
            "Training loss = 196.9128 || Validation loss = 221.2304 at Epoch 49\n",
            "Training loss = 185.2198 || Validation loss = 290.4928 at Epoch 50\n",
            "Training loss = 184.3139 || Validation loss = 185.6554 at Epoch 51\n",
            "Training loss = 200.5730 || Validation loss = 223.0002 at Epoch 52\n",
            "Training loss = 203.9454 || Validation loss = 211.8339 at Epoch 53\n",
            "Training loss = 183.0603 || Validation loss = 209.8003 at Epoch 54\n",
            "Training loss = 171.6487 || Validation loss = 154.9580 at Epoch 55\n",
            "Training loss = 213.6129 || Validation loss = 148.3308 at Epoch 56\n",
            "Training loss = 171.1792 || Validation loss = 143.6863 at Epoch 57\n",
            "Training loss = 174.3234 || Validation loss = 130.1623 at Epoch 58\n",
            "Training loss = 191.0592 || Validation loss = 276.8671 at Epoch 59\n",
            "Training loss = 156.4758 || Validation loss = 159.0677 at Epoch 60\n",
            "Training loss = 138.1939 || Validation loss = 218.1291 at Epoch 61\n",
            "Training loss = 200.0263 || Validation loss = 225.8415 at Epoch 62\n",
            "Training loss = 187.8057 || Validation loss = 171.5988 at Epoch 63\n",
            "Training loss = 174.1590 || Validation loss = 274.6933 at Epoch 64\n",
            "Training loss = 135.7833 || Validation loss = 180.6170 at Epoch 65\n",
            "Training loss = 186.5517 || Validation loss = 175.3582 at Epoch 66\n",
            "Training loss = 163.3916 || Validation loss = 181.9365 at Epoch 67\n",
            "Training loss = 131.4738 || Validation loss = 258.1127 at Epoch 68\n",
            "Training loss = 196.9546 || Validation loss = 151.4147 at Epoch 69\n",
            "Training loss = 187.4378 || Validation loss = 219.7911 at Epoch 70\n",
            "Training loss = 174.5926 || Validation loss = 145.6785 at Epoch 71\n",
            "Training loss = 170.3984 || Validation loss = 164.2827 at Epoch 72\n",
            "Training loss = 194.3358 || Validation loss = 168.6167 at Epoch 73\n",
            "Training loss = 151.5396 || Validation loss = 161.5698 at Epoch 74\n",
            "Training loss = 183.4727 || Validation loss = 195.3112 at Epoch 75\n",
            "Training loss = 151.6663 || Validation loss = 214.9475 at Epoch 76\n",
            "Training loss = 132.1234 || Validation loss = 162.9812 at Epoch 77\n",
            "Training loss = 146.9779 || Validation loss = 258.5964 at Epoch 78\n",
            "Training loss = 194.7099 || Validation loss = 121.5881 at Epoch 79\n",
            "Training loss = 185.3293 || Validation loss = 271.0004 at Epoch 80\n",
            "Training loss = 161.7610 || Validation loss = 128.1073 at Epoch 81\n",
            "Training loss = 127.6611 || Validation loss = 165.4970 at Epoch 82\n",
            "Training loss = 180.8035 || Validation loss = 188.1407 at Epoch 83\n",
            "Training loss = 140.5428 || Validation loss = 255.1453 at Epoch 84\n",
            "Training loss = 163.2162 || Validation loss = 146.7271 at Epoch 85\n",
            "Training loss = 149.8975 || Validation loss = 186.0403 at Epoch 86\n",
            "Training loss = 214.7851 || Validation loss = 152.1866 at Epoch 87\n",
            "Training loss = 219.5703 || Validation loss = 137.4948 at Epoch 88\n",
            "Training loss = 189.9345 || Validation loss = 282.6024 at Epoch 89\n",
            "Training loss = 168.5809 || Validation loss = 187.1324 at Epoch 90\n",
            "Training loss = 147.0811 || Validation loss = 170.9096 at Epoch 91\n",
            "Training loss = 178.0827 || Validation loss = 170.2683 at Epoch 92\n",
            "Training loss = 177.3193 || Validation loss = 186.3967 at Epoch 93\n",
            "Training loss = 149.4124 || Validation loss = 299.8058 at Epoch 94\n",
            "Training loss = 176.4591 || Validation loss = 293.4749 at Epoch 95\n",
            "Training loss = 172.4846 || Validation loss = 311.2644 at Epoch 96\n",
            "Training loss = 162.1535 || Validation loss = 202.2911 at Epoch 97\n",
            "Training loss = 204.2222 || Validation loss = 283.1560 at Epoch 98\n",
            "Training loss = 181.9830 || Validation loss = 285.3347 at Epoch 99\n",
            "Training loss = 178.4258 || Validation loss = 253.7774 at Epoch 100\n",
            "Training loss = 156.7820 || Validation loss = 211.4268 at Epoch 101\n",
            "Training loss = 157.3200 || Validation loss = 204.5767 at Epoch 102\n",
            "Training loss = 233.6347 || Validation loss = 287.9664 at Epoch 103\n",
            "Training loss = 190.0296 || Validation loss = 167.6378 at Epoch 104\n",
            "Training loss = 148.8412 || Validation loss = 161.6295 at Epoch 105\n",
            "Training loss = 147.1591 || Validation loss = 237.2011 at Epoch 106\n",
            "Training loss = 172.6248 || Validation loss = 198.4481 at Epoch 107\n",
            "Training loss = 188.3856 || Validation loss = 212.9348 at Epoch 108\n",
            "Training loss = 151.8920 || Validation loss = 221.6518 at Epoch 109\n",
            "Training loss = 189.8625 || Validation loss = 173.2237 at Epoch 110\n",
            "Training loss = 234.6133 || Validation loss = 160.5274 at Epoch 111\n",
            "Training loss = 185.4279 || Validation loss = 230.4970 at Epoch 112\n",
            "Training loss = 233.8683 || Validation loss = 267.3073 at Epoch 113\n",
            "Training loss = 150.5980 || Validation loss = 137.9125 at Epoch 114\n",
            "Training loss = 174.1882 || Validation loss = 117.1566 at Epoch 115\n",
            "Training loss = 165.3341 || Validation loss = 260.2131 at Epoch 116\n",
            "Training loss = 135.5790 || Validation loss = 187.9509 at Epoch 117\n",
            "Training loss = 140.0147 || Validation loss = 164.6541 at Epoch 118\n",
            "Training loss = 191.1018 || Validation loss = 158.4262 at Epoch 119\n",
            "Training loss = 179.8698 || Validation loss = 254.4198 at Epoch 120\n",
            "Training loss = 163.3234 || Validation loss = 273.4409 at Epoch 121\n",
            "Training loss = 180.4208 || Validation loss = 305.6438 at Epoch 122\n",
            "Training loss = 141.5741 || Validation loss = 207.0807 at Epoch 123\n",
            "Training loss = 169.4624 || Validation loss = 103.5002 at Epoch 124\n",
            "Training loss = 159.6900 || Validation loss = 188.1568 at Epoch 125\n",
            "Training loss = 146.2132 || Validation loss = 142.1981 at Epoch 126\n",
            "Training loss = 164.1039 || Validation loss = 201.2745 at Epoch 127\n",
            "Training loss = 160.9277 || Validation loss = 269.0913 at Epoch 128\n",
            "Training loss = 172.8031 || Validation loss = 202.4280 at Epoch 129\n",
            "Training loss = 160.2849 || Validation loss = 179.8293 at Epoch 130\n",
            "Training loss = 152.9022 || Validation loss = 226.7481 at Epoch 131\n",
            "Training loss = 168.2171 || Validation loss = 276.0031 at Epoch 132\n",
            "Training loss = 156.9883 || Validation loss = 280.5002 at Epoch 133\n",
            "Training loss = 204.9702 || Validation loss = 146.0017 at Epoch 134\n",
            "Training loss = 154.8248 || Validation loss = 194.7604 at Epoch 135\n",
            "Training loss = 199.6275 || Validation loss = 168.8210 at Epoch 136\n",
            "Training loss = 165.7915 || Validation loss = 193.7387 at Epoch 137\n",
            "Training loss = 169.4104 || Validation loss = 157.5118 at Epoch 138\n",
            "Training loss = 168.6451 || Validation loss = 231.5518 at Epoch 139\n",
            "Training loss = 152.2042 || Validation loss = 147.9233 at Epoch 140\n",
            "Training loss = 202.6027 || Validation loss = 168.9064 at Epoch 141\n",
            "Training loss = 170.1884 || Validation loss = 165.6947 at Epoch 142\n",
            "Training loss = 119.7170 || Validation loss = 147.3356 at Epoch 143\n",
            "Training loss = 183.0245 || Validation loss = 245.0299 at Epoch 144\n",
            "Training loss = 195.1773 || Validation loss = 208.8946 at Epoch 145\n",
            "Training loss = 153.6010 || Validation loss = 225.3365 at Epoch 146\n",
            "Training loss = 194.1493 || Validation loss = 177.6002 at Epoch 147\n",
            "Training loss = 164.1293 || Validation loss = 157.9169 at Epoch 148\n",
            "Training loss = 150.0557 || Validation loss = 220.9525 at Epoch 149\n",
            "Training loss = 184.0484 || Validation loss = 198.1492 at Epoch 150\n",
            "Training loss = 181.0519 || Validation loss = 249.8906 at Epoch 151\n",
            "Training loss = 213.3817 || Validation loss = 275.6283 at Epoch 152\n",
            "Training loss = 217.9397 || Validation loss = 169.0066 at Epoch 153\n",
            "Training loss = 176.4580 || Validation loss = 176.1210 at Epoch 154\n",
            "Training loss = 151.4917 || Validation loss = 182.6664 at Epoch 155\n",
            "Training loss = 178.4114 || Validation loss = 157.6227 at Epoch 156\n",
            "Training loss = 139.9303 || Validation loss = 218.4923 at Epoch 157\n",
            "Training loss = 167.2905 || Validation loss = 257.5407 at Epoch 158\n",
            "Training loss = 129.9926 || Validation loss = 192.7715 at Epoch 159\n",
            "Training loss = 196.3216 || Validation loss = 197.9285 at Epoch 160\n",
            "Training loss = 154.3075 || Validation loss = 195.3668 at Epoch 161\n",
            "Training loss = 156.1082 || Validation loss = 258.8111 at Epoch 162\n",
            "Training loss = 181.0762 || Validation loss = 136.9606 at Epoch 163\n",
            "Training loss = 192.9429 || Validation loss = 100.6266 at Epoch 164\n",
            "Training loss = 176.7534 || Validation loss = 244.1231 at Epoch 165\n",
            "Training loss = 156.4933 || Validation loss = 257.5921 at Epoch 166\n",
            "Training loss = 179.0555 || Validation loss = 152.9924 at Epoch 167\n",
            "Training loss = 193.1929 || Validation loss = 175.0872 at Epoch 168\n",
            "Training loss = 143.5170 || Validation loss = 218.1273 at Epoch 169\n",
            "Training loss = 161.7082 || Validation loss = 198.5265 at Epoch 170\n",
            "Training loss = 138.2834 || Validation loss = 288.1468 at Epoch 171\n",
            "Training loss = 170.7743 || Validation loss = 325.3633 at Epoch 172\n",
            "Training loss = 164.1143 || Validation loss = 288.1742 at Epoch 173\n",
            "Training loss = 174.5733 || Validation loss = 212.8831 at Epoch 174\n",
            "Training loss = 226.5551 || Validation loss = 147.0337 at Epoch 175\n",
            "Training loss = 145.7417 || Validation loss = 197.4548 at Epoch 176\n",
            "Training loss = 137.9902 || Validation loss = 118.8577 at Epoch 177\n",
            "Training loss = 212.2033 || Validation loss = 150.1248 at Epoch 178\n",
            "Training loss = 148.3495 || Validation loss = 136.2136 at Epoch 179\n",
            "Training loss = 187.4742 || Validation loss = 233.1085 at Epoch 180\n",
            "Training loss = 166.6241 || Validation loss = 274.2937 at Epoch 181\n",
            "Training loss = 137.3075 || Validation loss = 215.9700 at Epoch 182\n",
            "Training loss = 152.7863 || Validation loss = 238.9877 at Epoch 183\n",
            "Training loss = 161.1706 || Validation loss = 172.2540 at Epoch 184\n",
            "Training loss = 172.2063 || Validation loss = 228.9471 at Epoch 185\n",
            "Training loss = 142.3932 || Validation loss = 276.3579 at Epoch 186\n",
            "Training loss = 196.4969 || Validation loss = 159.7564 at Epoch 187\n",
            "Training loss = 165.7279 || Validation loss = 211.9211 at Epoch 188\n",
            "Training loss = 139.1947 || Validation loss = 131.7248 at Epoch 189\n",
            "Training loss = 148.3021 || Validation loss = 235.9130 at Epoch 190\n",
            "Training loss = 157.5827 || Validation loss = 179.5034 at Epoch 191\n",
            "Training loss = 191.1547 || Validation loss = 152.7113 at Epoch 192\n",
            "Training loss = 197.9259 || Validation loss = 125.8543 at Epoch 193\n",
            "Training loss = 157.4769 || Validation loss = 129.0023 at Epoch 194\n",
            "Training loss = 160.2499 || Validation loss = 150.5697 at Epoch 195\n",
            "Training loss = 205.8471 || Validation loss = 263.9422 at Epoch 196\n",
            "Training loss = 173.0444 || Validation loss = 255.8487 at Epoch 197\n",
            "Training loss = 177.6851 || Validation loss = 179.7703 at Epoch 198\n",
            "Training loss = 175.9294 || Validation loss = 135.5570 at Epoch 199\n",
            "Training loss = 151.0078 || Validation loss = 158.1505 at Epoch 200\n",
            "Training loss = 176.0309 || Validation loss = 174.1818 at Epoch 201\n",
            "Training loss = 139.7434 || Validation loss = 182.7217 at Epoch 202\n",
            "Training loss = 140.3981 || Validation loss = 166.1405 at Epoch 203\n",
            "Training loss = 168.8957 || Validation loss = 209.1304 at Epoch 204\n",
            "Training loss = 148.5516 || Validation loss = 171.0730 at Epoch 205\n",
            "Training loss = 193.6995 || Validation loss = 233.3839 at Epoch 206\n",
            "Training loss = 188.4996 || Validation loss = 237.5985 at Epoch 207\n",
            "Training loss = 177.0753 || Validation loss = 228.9558 at Epoch 208\n",
            "Training loss = 163.0136 || Validation loss = 286.2762 at Epoch 209\n",
            "Training loss = 176.1460 || Validation loss = 149.8070 at Epoch 210\n",
            "Training loss = 163.6778 || Validation loss = 191.8774 at Epoch 211\n",
            "Training loss = 171.4846 || Validation loss = 181.0045 at Epoch 212\n",
            "Training loss = 168.3299 || Validation loss = 182.1564 at Epoch 213\n",
            "Training loss = 158.0160 || Validation loss = 225.2822 at Epoch 214\n",
            "Training loss = 113.3266 || Validation loss = 261.5154 at Epoch 215\n",
            "Training loss = 120.2631 || Validation loss = 177.6771 at Epoch 216\n",
            "Training loss = 164.0259 || Validation loss = 245.0275 at Epoch 217\n",
            "Training loss = 143.8129 || Validation loss = 153.1886 at Epoch 218\n",
            "Training loss = 165.7749 || Validation loss = 194.5558 at Epoch 219\n",
            "Training loss = 162.9850 || Validation loss = 229.7872 at Epoch 220\n",
            "Training loss = 196.2499 || Validation loss = 159.4513 at Epoch 221\n",
            "Training loss = 181.2732 || Validation loss = 229.9211 at Epoch 222\n",
            "Training loss = 196.1610 || Validation loss = 181.4766 at Epoch 223\n",
            "Training loss = 200.4766 || Validation loss = 189.0398 at Epoch 224\n",
            "Training loss = 152.2146 || Validation loss = 177.7669 at Epoch 225\n",
            "Training loss = 162.4881 || Validation loss = 144.9387 at Epoch 226\n",
            "Training loss = 167.0388 || Validation loss = 192.3149 at Epoch 227\n",
            "Training loss = 168.2965 || Validation loss = 193.8566 at Epoch 228\n",
            "Training loss = 159.0515 || Validation loss = 123.3379 at Epoch 229\n",
            "Training loss = 144.0430 || Validation loss = 149.5442 at Epoch 230\n",
            "Training loss = 151.4293 || Validation loss = 219.6717 at Epoch 231\n",
            "Training loss = 167.4187 || Validation loss = 174.4850 at Epoch 232\n",
            "Training loss = 189.7009 || Validation loss = 223.3385 at Epoch 233\n",
            "Training loss = 179.2269 || Validation loss = 287.9034 at Epoch 234\n",
            "Training loss = 165.3612 || Validation loss = 240.9668 at Epoch 235\n",
            "Training loss = 167.2613 || Validation loss = 142.2000 at Epoch 236\n",
            "Training loss = 195.9415 || Validation loss = 153.2264 at Epoch 237\n",
            "Training loss = 125.1570 || Validation loss = 178.0575 at Epoch 238\n",
            "Training loss = 161.1266 || Validation loss = 215.2622 at Epoch 239\n",
            "Training loss = 163.0074 || Validation loss = 260.9673 at Epoch 240\n",
            "Training loss = 140.5745 || Validation loss = 206.5567 at Epoch 241\n",
            "Training loss = 135.0056 || Validation loss = 232.2516 at Epoch 242\n",
            "Training loss = 189.3657 || Validation loss = 182.7732 at Epoch 243\n",
            "Training loss = 143.4028 || Validation loss = 143.5133 at Epoch 244\n",
            "Training loss = 154.0567 || Validation loss = 210.9824 at Epoch 245\n",
            "Training loss = 195.3947 || Validation loss = 146.4134 at Epoch 246\n",
            "Training loss = 151.9807 || Validation loss = 130.5105 at Epoch 247\n",
            "Training loss = 158.2849 || Validation loss = 183.0505 at Epoch 248\n",
            "Training loss = 152.4734 || Validation loss = 120.3153 at Epoch 249\n",
            "Training loss = 138.8295 || Validation loss = 235.5487 at Epoch 250\n",
            "Training loss = 165.6739 || Validation loss = 147.3593 at Epoch 251\n",
            "Training loss = 126.5611 || Validation loss = 203.1980 at Epoch 252\n",
            "Training loss = 155.9864 || Validation loss = 160.4018 at Epoch 253\n",
            "Training loss = 162.0002 || Validation loss = 191.4633 at Epoch 254\n",
            "Training loss = 151.1773 || Validation loss = 178.7666 at Epoch 255\n",
            "Training loss = 156.3179 || Validation loss = 265.4825 at Epoch 256\n",
            "Training loss = 152.4290 || Validation loss = 142.9233 at Epoch 257\n",
            "Training loss = 168.4978 || Validation loss = 267.3860 at Epoch 258\n",
            "Training loss = 136.1174 || Validation loss = 286.0976 at Epoch 259\n",
            "Training loss = 166.5254 || Validation loss = 142.1882 at Epoch 260\n",
            "Training loss = 144.4665 || Validation loss = 142.2129 at Epoch 261\n",
            "Training loss = 139.2181 || Validation loss = 212.7841 at Epoch 262\n",
            "Training loss = 185.8051 || Validation loss = 138.1517 at Epoch 263\n",
            "Training loss = 208.6619 || Validation loss = 273.9156 at Epoch 264\n",
            "Training loss = 175.6212 || Validation loss = 197.0469 at Epoch 265\n",
            "Training loss = 153.1140 || Validation loss = 304.2437 at Epoch 266\n",
            "Training loss = 152.0493 || Validation loss = 167.5465 at Epoch 267\n",
            "Training loss = 176.3120 || Validation loss = 128.0615 at Epoch 268\n",
            "Training loss = 197.6083 || Validation loss = 168.8891 at Epoch 269\n",
            "Training loss = 207.0997 || Validation loss = 149.9746 at Epoch 270\n",
            "Training loss = 147.3642 || Validation loss = 219.7794 at Epoch 271\n",
            "Training loss = 159.5640 || Validation loss = 123.4684 at Epoch 272\n",
            "Training loss = 168.5596 || Validation loss = 149.3749 at Epoch 273\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-236-35c0978a4b3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mstep_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Run the forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfgfZjAYsDGO",
        "colab_type": "code",
        "outputId": "3a2c4b3f-4525-4ccc-9774-f1ae25518998",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "## test dataset \n",
        "# test_dataset = NoisyImageDataset(\"/content/test_data.csv\",\n",
        "                                #  \"/content/PolyU-Real-World-Noisy-Images-Dataset-master/CroppedImages\")\n",
        "\n",
        "\n",
        "# test_dataset = NoisyImageDataset(\"/content/test_data.csv\",\n",
        "#                                  \"/content/original/\")\n",
        "\n",
        "test_dataset = NoisyImageDataset(\"/content/train_data.csv\",\"/content/CBSD68-dataset-master/CBSD68\")\n",
        "\n",
        "sample = test_dataset[2]\n",
        "\n",
        "plt.imshow(sample[\"noisy_image\"].numpy().astype(\"uint8\").transpose((1,2,0)))\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(sample[\"original_image\"].numpy().astype(\"uint8\").transpose((1,2,0)))\n",
        "plt.show()\n",
        "\n",
        "real, noisy = sample[\"original_image\"], sample[\"noisy_image\"]"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My1X986isMlZ",
        "colab_type": "code",
        "outputId": "e4dbfac3-8001-42f9-f3d6-832a60e859a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "source": [
        "## PSNR calculations\n",
        "denoised_img = model(noisy.cuda().unsqueeze(0)).cpu().squeeze().detach().numpy().transpose(1, 2, 0)\n",
        "\n",
        "plt.imshow(denoised_img.astype(\"uint8\"))\n",
        "plt.show()\n",
        "\n",
        "from skimage.measure import compare_psnr,compare_ssim\n",
        "\n",
        "real = real.numpy().transpose(1, 2, 0)\n",
        "noisy = noisy.numpy().transpose(1, 2, 0)\n",
        "print(real.shape, noisy.shape)\n",
        "h,w,_ = noisy.shape\n",
        "noisy = noisy[8: h-8,8:w-8]\n",
        "print(real.shape, noisy.shape)\n",
        "\n",
        "\n",
        "\n",
        "real_psnr = compare_psnr(real,noisy ,255)\n",
        "model_psnr = compare_psnr(real, denoised_img,255)\n",
        "\n",
        "real_ssim = compare_ssim(X=real,Y=noisy ,data_range=255,multichannel=True)\n",
        "model_ssim = compare_ssim(X=real,Y=denoised_img,data_range=255,multichannel=True)\n",
        "\n",
        "\n",
        "print(real_psnr,model_psnr)\n",
        "print(real_ssim,model_ssim)"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAATtklEQVR4nO3dfXBcZ3XH8e/ZXcmSLL8bQhInTWCA\nNtBSMi4TKKShadOQMpjO8EeY0oaXGYa2UOjQMqHMANO/eCt9LwyFtKENBAqhZJhQYl477TSG4DgJ\nzgs2IU1snFiWZMmSvFrt7ukfe80silbWuffuRvD8PjMarXafZ59n79XZu3vvPfeYuyMiP/sqT/YE\nRGQwFOwiiVCwiyRCwS6SCAW7SCJqgxxs546tfuGF54X6tNut8DjtVjvUvlK18BjVanzRWXwY3GOv\npTNOjoGC8hzFyXPcx9vxXlbJsQ0LLue7KtXwEM9rNMJ9pqamY+1PzjM3X1/xH2CgwX7hhefxP9/6\nZKjP3Km58Din5+dD7cfGN4TH2LptW7hPtRIPwqWlerjP8HB8tUZjqtlshsdo5XiDqC8uhfuMjI6E\n+7SDy3nz2Hh4jK8eORLu86lPfT7U/kP/eFvPx/QxXiQRCnaRRBQKdjO72sweNLPDZnZ9WZMSkfLl\nDnYzqwL/ALwMuAR4tZldUtbERKRcRbbsLwAOu/tD7t4Abgb2lDMtESlbkWA/H3i06+8j2X0/wcze\naGZ3mtmdJyZjhxFEpDx930Hn7h9z993uvnvnjvjhKhEpR5FgPwpc0PX3ruw+EVmHigT7d4BnmtnF\nZjYMXAvcWs60RKRsuc+gc/emmb0Z+ApQBW5w94OlzUxESlXodFl3vw3ofX6eiKwbAz033r3NUjAZ\nIEe+CbvOPyfUPkdOA1aNn+c9Nho/B7+xFB9nbi6eT9AO5tucXjgdHmMpmKAE0M6R01OrxM/bbyzG\n/i8n6vHX/+DhH4b7HDt+PNR+aZWcBZ0uK5IIBbtIIhTsIolQsIskQsEukggFu0giFOwiiVCwiyRC\nwS6SCAW7SCIU7CKJULCLJGKgiTCtZpOpycdDfcY3bgyPMzwUy2xptuKVOhr1ePGG2my8jy3Ek0c8\nx1t4ox1MULL4vFoeL/gwtmE03Mdb8XGmp46F2s9OxQqRAByfiCW1AJx34QVnb9RlaHh/z8e0ZRdJ\nhIJdJBFFrht/gZl9w8zuM7ODZvbWMicmIuUq8p29Cbzd3feb2Sbgu2a2193vK2luIlKi3Ft2dz/m\n7vuz26eA+1nhuvEisj6U8p3dzC4Cng/sW+GxHxeJmJyeLWM4EcmhcLCb2TjweeBt7v6EaO4uErFj\n2+aiw4lITkWruA7RCfSb3P2WcqYkIv1QZG+8AZ8A7nf3D5c3JRHphyJb9l8Ffg/4dTM7kP1cU9K8\nRKRkRSrC/DeQ46reIvJkGOi58UtLDSaOHQn1qZ5/bnicmZnYufHzlXghhnaO869HR+JFIkY2DIf7\nLC7Gz8Gvn14M9oi/z7dyFInIU4yiFTzPH6DdjM2tvhg/N77RiC5jmJ+ZCbVvt1o9H9PpsiKJULCL\nJELBLpIIBbtIIhTsIolQsIskQsEukggFu0giFOwiiVCwiyRCwS6SCAW7SCIGmghTrRgbR4ZCfRbn\npsPjLMSGYMvmTeExGs14ssX8bDypY35kJNxnodUM95k7FUvsaFt8OzFciycC1evx5JGF+fjlz+rB\nJJXFRjypx2qxBC2ATVu3htpXqr3H0JZdJBEKdpFEKNhFElHG1WWrZnaXmX2pjAmJSH+UsWV/K50C\nESKyjhW9lPQu4LeBj5czHRHpl6Jb9r8G3gH0PA7RXRFm6uRcweFEJK8i141/OXDc3b+7WrvuijDb\nt47nHU5ECip63fhXmNnDwM10rh//b6XMSkRKV6SK6zvdfZe7XwRcC3zd3V9T2sxEpFQ6zi6SiFLO\njXf3bwLfLOO5RKQ/BpoIc3B0lOc+55JQn2Yrnghx8uRUqP3k5InwGEM5khqmJ4+H+wwPx5NHqjn6\nbH/KOaH2MzPxpJ652XiCyulGjuo28/GjPnMLsUSgPAk6tQ3xpKbtO3fGxqj1Dml9jBdJhIJdJBEK\ndpFEKNhFEqFgF0mEgl0kEQp2kUQo2EUSoWAXSYSCXSQRCnaRRCjYRRIx0ESYS9vOHY1YtZJ6O17d\npDoUrDozG0+caA/HF93Yxo3hPriFuywuxqvVnDo1E2o/M7MQHqO1FF+X0ycnwn2WllrhPlOTseSp\nhWAFGYDNW3aE+wyPDIfaW6X3/4u27CKJULCLJKLopaS3mtnnzOwBM7vfzF5Y1sREpFxFv7P/DfCf\n7v4qMxsGxkqYk4j0Qe5gN7MtwOXAawHcvQHE9wyJyEAU+Rh/MTAB/HNW6+3jZvaE3c3dRSJOTJ4s\nMJyIFFEk2GvApcBH3P35wDxw/fJG3UUidu6IFZYXkfIUCfYjwBF335f9/Tk6wS8i61CRIhGPAY+a\n2bOzu64E7itlViJSuqJ7498C3JTtiX8IeF3xKYlIPxQKdnc/AOwuaS4i0kc6g04kEQNNhGm2Wpw4\nGTv85jkSYZxYIsTYWDxBpdWMJ1u0K/EqMjt2xJMnHn3kSLhPM7iYp6fjh1F/dDQ+L2/FlzM5qvXM\nLgQr3LQ9PMbkiXhSD5VYUldrlRWpLbtIIhTsIolQsIskQsEukggFu0giFOwiiVCwiyRCwS6SCAW7\nSCIU7CKJULCLJELBLpKIgSbCuDutViyBoNVsh8cZqsYSIUY2jYfHoB2fF6tU6+il1cqRPLP9qeE+\ns3OnQu0XZmMVZACWTsevR1rJsTlaXIxXa9lQiVVeWVyqh8eYPz0f7tMIJty0Vkkc0pZdJBEKdpFE\nFK0I8ydmdtDMvmdmnzazkbImJiLlyh3sZnY+8MfAbnd/LlAFri1rYiJSrqIf42vAqJnV6JR++lHx\nKYlIPxS5lPRR4EPAI8AxYMbdb1/errsizNT0bP6ZikghRT7GbwP20CkDdR6w0cxes7xdd0WY7ds2\n55+piBRS5GP8bwA/dPcJd18CbgFeVM60RKRsRYL9EeAyMxszM6NTEeb+cqYlImUr8p19H536bvuB\ne7Pn+lhJ8xKRkhWtCPMe4D0lzUVE+mig58ZXqzU2boyVba4vzIXHWWwshNrPTMULHmzZvCXcZ7gW\nO/8a4NRC7LUAeI4CBgvzsSIJniM1wJfiBT8qG2JFEgCqFs8niL6cWiUeOtaKf5Cuz8WOYLV1bryI\nKNhFEqFgF0mEgl0kEQp2kUQo2EUSoWAXSYSCXSQRCnaRRCjYRRKhYBdJhIJdJBEDTYSpmDE6GrsA\nrbXiGRfDwcoCC/X4xfvn5uIJKps3xd9bN1TjiSCzp+KJPdMnToTat+pL4THGx+IXH27U4wUfhmvx\nRJhWcLvX9HjBj4r3TlLpxYJFVVYdv7RnEpF1TcEukggFu0gizhrsZnaDmR03s+913bfdzPaa2aHs\n97b+TlNEilrLlv1fgKuX3Xc98DV3fybwtexvEVnHzhrs7v5fwNSyu/cAN2a3bwReWfK8RKRkeb+z\nn+Pux7LbjwHn9GrYXRFmYjJ+SEhEylF4B527O9DzYGB3RZin7IhdbFJEypM32B83s3MBst/Hy5uS\niPRD3mC/Fbguu30d8MVypiMi/bKWQ2+fBv4XeLaZHTGzNwDvA37TzA7Rqfn2vv5OU0SKOuu58e7+\n6h4PXVnyXESkjwaaCOMY7eCQlaF48sTExPIjhauzeE4DO7aMhft4M57UcGIqlqACUK/HqrsAWHBq\n3o4ndYyOxJfZcC2+/uvNeJJOK5hw08iRCDS/UA/3mZuPJWm1V0kc0+myIolQsIskQsEukggFu0gi\nFOwiiVCwiyRCwS6SCAW7SCIU7CKJULCLJELBLpIIBbtIIgaaCGNWoVYZDfUZHo21Bzjv3NjLOnTo\ngfAYsyfjl9jauWU83Ofoo4+E+0xOTIT7bN4au4pQtTYcHuPU7Klwn9pQvCJOs9EM94nm9bRyJNuY\nx7ettWCIGr2zurRlF0mEgl0kEXmLRHzQzB4ws3vM7AtmpitJiqxzeYtE7AWe6+6/BHwfeGfJ8xKR\nkuUqEuHut7v7mb0gdwC7+jA3ESlRGd/ZXw98udeD3UUiTpyYLmE4EcmjULCb2buAJnBTrzbdRSJ2\n7lT9R5EnS+7j7Gb2WuDlwJVZVRgRWcdyBbuZXQ28A/g1d18od0oi0g95i0T8PbAJ2GtmB8zso32e\np4gUlLdIxCf6MBcR6SOdQSeSiMEmwgBVqqE+SwvxXQKnTsYO8Vk7vn9xLkdSR/t0vCLIQo4+LeLJ\nI0vN2Pt+ox6fV6UaT56pVeL/oq1K76oovVQrsf8Bb8fLCFUsvm0drsXWpa1S3khbdpFEKNhFEqFg\nF0mEgl0kEQp2kUQo2EUSoWAXSYSCXSQRCnaRRCjYRRKhYBdJhIJdJBEDTYSp1xc59P0HQ302Dm8I\nj7NhKJakMFSNJecAnJ6PVwSZOj119kbL1Jfi43iOhIvjxydD7eNLDGpD8X+3dry4C81WsLwL4MFk\nqKEcCTqVHMkzhJO0erfXll0kEQp2kUTkqgjT9djbzczNbGd/piciZclbEQYzuwC4CoiXGRWRgctV\nESbzV3SuMKvLSIv8FMj1nd3M9gBH3f3uNbT9cUWY6ZMzeYYTkRKEg93MxoA/B969lvbdFWG2bd0S\nHU5ESpJny/4M4GLgbjN7mE5Rx/1m9rQyJyYi5QqfGeDu9wJPPfN3FvC73f1EifMSkZLlrQgjIj9l\n8laE6X78otJmIyJ9M9Bz408vLHDwrgOhPhPHfhQe5/IrXhJqXx2KFy9oL8ULEVQsPs6msdFwHyx+\nNHRpKFaMYGlxMTzGYqMR7uPxRUY1R25Ai9j6bLbj67+d45z9WiX2WgwViRBJnoJdJBEKdpFEKNhF\nEqFgF0mEgl0kEQp2kUQo2EUSoWAXSYSCXSQRCnaRRCjYRRIx0ESY8fGNXHbZC0N9PnvzZ8Pj3HX3\nEy6Eu6pf+MWfD49RyZE80zpdD/dZbMQTTqjG38MrweSRHHkgjOQo+GE5qlF4jslVgmUvWh5PNmo2\n4wU/xsdjiVCVVda9tuwiiVCwiyQid5EIM3uLmT1gZgfN7AP9m6KIlCFXkQgzeymwB3ieuz8H+FD5\nUxORMuUtEvEHwPvcfTFrc7wPcxOREuX9zv4s4CVmts/MvmVmv9KrYXeRiMnp2ZzDiUhReYO9BmwH\nLgP+DPisma148avuIhE7tm3OOZyIFJU32I8At3jHt4E2oEquIutY3mD/D+ClAGb2LGAYUJEIkXXs\nrGfQZUUirgB2mtkR4D3ADcAN2eG4BnCde45TikRkYIoUiXhNyXMRkT7SGXQiibBBfvo2swng/1Z4\naCdP7nd+ja/xf1bG/zl3f8pKDww02HsxszvdfbfG1/gav3/0MV4kEQp2kUSsl2D/mMbX+Bq/v9bF\nd3YR6b/1smUXkT5TsIskYqDBbmZXm9mDZnbYzK5f4fENZvaZ7PF9ZnZRiWNfYGbfMLP7sqvrvHWF\nNleY2YyZHch+3l3W+NnzP2xm92bPfecKj5uZ/W32+u8xs0tLHPvZXa/rgJnNmtnblrUp9fWvdJUj\nM9tuZnvN7FD2e1uPvtdlbQ6Z2XUljv/B7ApL95jZF8xsa4++q66rAuO/18yOdi3ja3r0XTVWcnH3\ngfwAVeAHwNPpJM7cDVyyrM0fAh/Nbl8LfKbE8c8FLs1ubwK+v8L4VwBf6uMyeBjYucrj1wBfBoxO\n+vC+Pq6Lx+icgNG31w9cDlwKfK/rvg8A12e3rwfev0K/7cBD2e9t2e1tJY1/FVDLbr9/pfHXsq4K\njP9e4E/XsH5WjZU8P4Pcsr8AOOzuD7l7A7iZzqWtuu0Bbsxufw64sleefJS7H3P3/dntU8D9wPll\nPHeJ9gCf9I47gK1mdm4fxrkS+IG7r3Q2Y2l85ascda/jG4FXrtD1t4C97j7l7tPAXpZdGi3v+O5+\nu7s3sz/vAHZFn7fI+Gu0llgJG2Swnw882vX3EZ4YbD9uk62QGWBH2RPJvh48H9i3wsMvNLO7zezL\nZvackod24HYz+66ZvXGFx9eyjMpwLfDpHo/18/UDnOPux7LbjwHnrNBmUMvh9XQ+Sa3kbOuqiDdn\nXyNu6PE1pi+vP7kddGY2DnweeJu7L79O1n46H22fB/wdnbz9Mr3Y3S8FXgb8kZldXvLzn5WZDQOv\nAP59hYf7/fp/gnc+sz4px37N7F1AE7ipR5N+rauPAM8Afhk4BvxlSc97VoMM9qPABV1/78ruW7GN\nmdWALcBkWRMwsyE6gX6Tu9+y/HF3n3X3uez2bcCQmZV2BR53P5r9Pg58gc7HtW5rWUZFvQzY7+6P\nrzC/vr7+zONnvppkv1e6WGlfl4OZvRZ4OfC72RvOE6xhXeXi7o+7e8vd28A/9Xjevrz+QQb7d4Bn\nmtnF2dblWuDWZW1uBc7seX0V8PVeKyMq++7/CeB+d/9wjzZPO7OPwMxeQGf5lPJmY2YbzWzTmdt0\ndhQtr1N1K/D72V75y4CZro+8ZXk1PT7C9/P1d+lex9cBX1yhzVeAq8xsW/Yx96rsvsLM7GrgHcAr\n3H2hR5u1rKu843fvg/mdHs+7lliJK7qHL7h38ho6e8F/ALwru+8v6Cx4gBE6Hy8PA98Gnl7i2C+m\n85HxHuBA9nMN8CbgTVmbNwMH6ez9vAN4UYnjPz173ruzMc68/u7xDfiHbPncC+wueflvpBO8W7ru\n69vrp/OmcgxYovO98w109sF8DTgEfBXYnrXdDXy8q+/rs/+Dw8DrShz/MJ3vw2f+B84c/TkPuG21\ndVXS+P+ardt76ATwucvH7xUrRX90uqxIIpLbQSeSKgW7SCIU7CKJULCLJELBLpIIBbtIIhTsIon4\nfyFyGIfRJc/UAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(17, 17, 3) (33, 33, 3)\n",
            "(17, 17, 3) (17, 17, 3)\n",
            "15.165599038905864 23.185159988493385\n",
            "0.3191612901244631 0.7783553024364972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzmn2hNRsMn3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "008c4fc5-0448-4fc8-dcf1-e849fdf8fa3a"
      },
      "source": [
        "## psnr stats\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "psnrs = []\n",
        "ssims = []\n",
        "\n",
        "for sample in tqdm(test_dataset):\n",
        "  real, noisy = sample[\"original_image\"], sample[\"noisy_image\"]\n",
        "  ## PSNR calculations\n",
        "  denoised_img = model(noisy.cuda().unsqueeze(0)).cpu().squeeze().detach().numpy().transpose(1, 2, 0)\n",
        "\n",
        "  real = real.numpy().transpose(1, 2, 0)\n",
        "  noisy = noisy.numpy().transpose(1, 2, 0)\n",
        "  # print(real.shape, noisy.shape)\n",
        "  h,w,_ = noisy.shape\n",
        "  noisy = noisy[8: h-8,8:w-8]\n",
        "  # print(real.shape, noisy.shape)\n",
        "\n",
        "\n",
        "\n",
        "  real_psnr = compare_psnr(real,noisy ,255)\n",
        "  model_psnr = compare_psnr(real, denoised_img,255)\n",
        "\n",
        "  psnrs.append((real_psnr,model_psnr))\n",
        "\n",
        "  real_ssim = compare_ssim(X=real,Y=noisy ,data_range=255,multichannel=True)\n",
        "  model_ssim = compare_ssim(X=real,Y=denoised_img,data_range=255,multichannel=True)\n",
        "\n",
        "  ssims.append((real_ssim,model_ssim))"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 67/67 [00:02<00:00, 29.05it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ttWXsSbBI_X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b218c125-555a-471f-a31f-8d18bc8d42cd"
      },
      "source": [
        "s1 = [0,0]\n",
        "s2 = [0,0]\n",
        "\n",
        "for i in range(len(psnrs)):\n",
        "  s1[0]+= psnrs[i][0]\n",
        "  s1[1]+= psnrs[i][1]\n",
        "  s2[0]+= ssims[i][0]\n",
        "  s2[1]+= ssims[i][1]\n",
        "\n",
        "n = len(psnrs)\n",
        "print(n)\n",
        "\n",
        "print(s1[0]/n,s1[1]/n)\n",
        "print(s2[0]/n,s2[1]/n)\n"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "67\n",
            "28.260697395304945 33.33608908764743\n",
            "0.759813037313774 0.9310548294070953\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skbPI0t1BJKI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## using dn_resnet 3 layer \n",
        "\n",
        "##psnr averages with 50 sigma, 200 crop size\n",
        "14.973042415349417 25.678599595017495\n",
        "0.25360402872293836 0.7169126150233502\n",
        "\n",
        "##psnr averages with 25 sigma, 200 crop size\n",
        "20.489541131226048 29.459506209247255\n",
        "0.4543074518017813 0.8514222434602313\n",
        "\n",
        "##psnr averages with 10 sigma, 200 crop size\n",
        "28.260697395304945 33.33608908764743\n",
        "0.759813037313774 0.9310548294070953\n",
        "\n",
        "##psnr averages with 50 sigma, 33 crop size\n",
        "15.047263794208707 26.689931811823588\n",
        "0.22653035603369392 0.6985790887565936"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSG4pYlzBJPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## using dn_resnet 3 layer \n",
        "\n",
        "##psnr averages with 50 sigma, 200 crop size\n",
        "14.936671462827626 25.587376709598537\n",
        "0.24620526247389574 0.7081614024709503\n",
        "\n",
        "##psnr averages with 25 sigma, 200 crop size\n",
        "20.513676879788218 29.116933436963734\n",
        "0.4654254023410544 0.8483339176769287\n",
        "\n",
        "##psnr averages with 10 sigma, 200 crop size\n",
        "28.25300504116213 32.842224416743036\n",
        "0.7517520790173152 0.9220117575097961\n",
        "\n",
        "##psnr averages with 50 sigma, 33 crop size\n",
        "14.97794610257495 26.058241500922545\n",
        "0.23024619624481021 0.7039497167777483"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDSXX0NbBJS2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "838dd769-fc27-462e-bc5c-09d087850b1e"
      },
      "source": [
        "## save images\n",
        "\n",
        "real_psnrs = []\n",
        "model_psnrs = []\n",
        "real_ssims = []\n",
        "model_ssims = []\n",
        "test_dataset = NoisyImageDataset(\"/content/test_data.csv\",\"/content/CBSD68-dataset-master/CBSD68\")\n",
        "\n",
        "c = 0\n",
        "for sample in tqdm(test_dataset):\n",
        "  real, noisy = sample[\"original_image\"], sample[\"noisy_image\"]\n",
        "  ## PSNR calculations\n",
        "  denoised_img = model2(noisy.cuda().unsqueeze(0)).cpu().squeeze().detach().numpy().transpose(1, 2, 0)\n",
        "\n",
        "  real = real.numpy().transpose(1, 2, 0)\n",
        "  noisy = noisy.numpy().transpose(1, 2, 0)\n",
        "  # print(real.shape, noisy.shape)\n",
        "  h,w,_ = noisy.shape\n",
        "  noisy = noisy[8: h-8,8:w-8]\n",
        "  # print(real.shape, noisy.shape)\n",
        "  real_psnr = compare_psnr(real,noisy ,255)\n",
        "  model_psnr = compare_psnr(real, denoised_img,255)\n",
        "\n",
        "  real_psnrs.append(real_psnr)\n",
        "  model_psnrs.append(model_psnr)\n",
        "\n",
        "  real_ssim = compare_ssim(X=real,Y=noisy ,data_range=255,multichannel=True)\n",
        "  model_ssim = compare_ssim(X=real,Y=denoised_img,data_range=255,multichannel=True)\n",
        "\n",
        "  real_ssims.append(real_ssim)\n",
        "  model_ssims.append(model_ssim)\n",
        "  \n",
        "  denoised_img = denoised_img.astype(\"uint8\")\n",
        "  io.imsave('/content/drive/My Drive/dn_resnet_results/dn_resnet_150_fine_tuned/50/{}.jpg'.format(c), denoised_img)\n",
        "\n",
        "  c+=1\n",
        "\n",
        "df = pd.DataFrame({\"r_p\":real_psnrs,\"m_p\":model_psnrs,\"r_s\":real_ssims,\"m_s\":model_ssims})\n",
        "df.to_csv(\"/content/drive/My Drive/dn_resnet_results/dn_resnet_150_fine_tuned/50/info.csv\")"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [00:01<00:00,  8.65it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kd_ENRPnBJap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "## create 9 image plots for 10, 25 and 50 sigmas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ8uTY4HEy2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfguzkq8Flne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qIdDrWnIbay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}